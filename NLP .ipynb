{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d21593",
   "metadata": {},
   "source": [
    "# NLP --Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcb3a865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'nltk' from 'C:\\\\Users\\\\GOPINATH V GOWDA\\\\anaconda3\\\\lib\\\\site-packages\\\\nltk\\\\__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b6cc6de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gopinath , .@doing good #job, $keep going, best luck'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data='Gopinath your , .@doing good #job, $keep going, best of luck '\n",
    "noise_list = [\"is\", \"a\", \"this\",'an','am','for','your','of'] \n",
    "def _remove_noise(input_text):\n",
    "    words = input_text.split() \n",
    "    noise_free_words = [word for word in words if word not in noise_list] \n",
    "    noise_free_text = \" \".join(noise_free_words) \n",
    "    return noise_free_text\n",
    "_remove_noise(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fe1d6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6aac19f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gopinath your , .@doing good , $keep going, best of luck'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _remove_regex(input_text, regex_pattern):\n",
    "    urls = re.finditer(regex_pattern, input_text) \n",
    "    for i in urls: \n",
    "        input_text = re.sub(i.group().strip(), '', input_text)\n",
    "    return input_text\n",
    "\n",
    "regex_pattern = \"#[\\w]*\"  \n",
    "\n",
    "_remove_regex(\"Gopinath your , .@doing good #job, $keep going, best of luck\", regex_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ca3d8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 2), match='AV'>\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import re\n",
    "\n",
    "# matching AV in the given sentence\n",
    "result = re.match(r'AV', 'AV Analytics Vidhya AV')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "35a6cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.search(r'na', 'AnalyticsVidhyaAV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3ad5a856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(1, 3), match='na'>\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bed1369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['An']\n"
     ]
    }
   ],
   "source": [
    "result = re.findall(r'An', 'AV Analytics Vidhya AV')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "20b106b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' is best']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(r'gopi', 'gopi is best')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ed3c0529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the World is best'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine string by removing mentionnedone\n",
    "result=re.sub(r'gopi','the World','gopi is best')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e757ba7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['an']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern=re.compile('an')\n",
    "result=pattern.findall('AV Analytics Vidhya AV') \n",
    "print(result)\n",
    "result2=pattern.findall('AV is largest analytics community of India')\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "adfed52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'remove this  #from analytics vidhya'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "def _remove_regex(input_text, regex_pattern):\n",
    "    urls = re.finditer(regex_pattern, input_text) \n",
    "    for i in urls: \n",
    "        input_text = re.sub(i.group().strip(), '', input_text)\n",
    "    return input_text\n",
    "\n",
    "regex_pattern = \"@[\\w]*\"  \n",
    "_remove_regex(\"remove this @hashtag #from analytics vidhya\", regex_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b3962966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "defc3da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer \n",
    "stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "84a418ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multipli'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363818ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d970a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"multiplying\" \n",
    "lem.lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2fc1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    " wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d97d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl.lemmatize('aardwolves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75e5da84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensimNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading gensim-4.1.2-cp39-cp39-win_amd64.whl (24.0 MB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\gopinath v gowda\\anaconda3\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\gopinath v gowda\\anaconda3\\lib\\site-packages (from gensim) (1.22.2)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Collecting Cython==0.29.23\n",
      "  Downloading Cython-0.29.23-cp39-cp39-win_amd64.whl (1.7 MB)\n",
      "Installing collected packages: smart-open, Cython, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.24\n",
      "    Uninstalling Cython-0.29.24:\n",
      "      Successfully uninstalled Cython-0.29.24\n",
      "Successfully installed Cython-0.29.23 gensim-4.1.2 smart-open-5.2.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a60e4dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "sentences = [['data', 'science'], ['vidhya', 'science', 'data', 'analytics'],['machine', 'learning'], ['deep', 'learning']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86f4e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on your corpus  \n",
    "model = Word2Vec(sentences, min_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feae1a67",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Word2Vec' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_9172/2096191389.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Word2Vec' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(model['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7b03c47",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Word2Vec' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_9172/3760271165.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Word2Vec' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(model['sentence'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af3f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2585391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"Albert Einstein was born in Ulm, Germany in 1879.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "921bccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e67a3f5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_9148/1596495097.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_9148/1596495097.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    tokens[]\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb09033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
