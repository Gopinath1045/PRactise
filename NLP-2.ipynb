{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "782c32c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph =  \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them. \n",
    "               Why? Because we respect the freedom of others.That is why my \n",
    "               first vision is that of freedom. I believe that India got its first vision of \n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "18551e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer \n",
    "stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e39c9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "31dc67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "52042e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "sentences= nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "12443818",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "corpus = []\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [stem.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1cfc0f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three vision india',\n",
       " 'year histori peopl world come invad us captur land conquer mind',\n",
       " 'alexand onward greek turk mogul portugues british french dutch came loot us took',\n",
       " 'yet done nation',\n",
       " 'conquer anyon',\n",
       " 'grab land cultur histori tri enforc way life',\n",
       " '',\n",
       " 'respect freedom other first vision freedom',\n",
       " 'believ india got first vision start war independ',\n",
       " 'freedom must protect nurtur build',\n",
       " 'free one respect us',\n",
       " 'second vision india develop',\n",
       " 'fifti year develop nation',\n",
       " 'time see develop nation',\n",
       " 'among top nation world term gdp',\n",
       " 'percent growth rate area',\n",
       " 'poverti level fall',\n",
       " 'achiev global recognis today',\n",
       " 'yet lack self confid see develop nation self reliant self assur',\n",
       " 'incorrect',\n",
       " 'third vision',\n",
       " 'india must stand world',\n",
       " 'believ unless india stand world one respect us',\n",
       " 'strength respect strength',\n",
       " 'must strong militari power also econom power',\n",
       " 'must go hand hand',\n",
       " 'good fortun work three great mind',\n",
       " 'dr vikram sarabhai dept',\n",
       " 'space professor satish dhawan succeed dr brahm prakash father nuclear materi',\n",
       " 'lucki work three close consid great opportun life',\n",
       " 'see four mileston career']"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9744f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "wordnet=WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "corpus = []\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lem.lemmatize(word,'v') for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "78fff66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three visions india',\n",
       " 'years history people world come invade us capture land conquer mind',\n",
       " 'alexander onwards greeks turks moguls portuguese british french dutch come loot us take',\n",
       " 'yet do nation',\n",
       " 'conquer anyone',\n",
       " 'grab land culture history try enforce way life',\n",
       " '',\n",
       " 'respect freedom others first vision freedom',\n",
       " 'believe india get first vision start war independence',\n",
       " 'freedom must protect nurture build',\n",
       " 'free one respect us',\n",
       " 'second vision india development',\n",
       " 'fifty years develop nation',\n",
       " 'time see develop nation',\n",
       " 'among top nations world term gdp',\n",
       " 'percent growth rate areas',\n",
       " 'poverty level fall',\n",
       " 'achievements globally recognise today',\n",
       " 'yet lack self confidence see develop nation self reliant self assure',\n",
       " 'incorrect',\n",
       " 'third vision',\n",
       " 'india must stand world',\n",
       " 'believe unless india stand world one respect us',\n",
       " 'strength respect strength',\n",
       " 'must strong military power also economic power',\n",
       " 'must go hand hand',\n",
       " 'good fortune work three great mind',\n",
       " 'dr vikram sarabhai dept',\n",
       " 'space professor satish dhawan succeed dr brahm prakash father nuclear material',\n",
       " 'lucky work three closely consider great opportunity life',\n",
       " 'see four milestones career']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "67519cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the TF-IDF model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2e5e771f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.31833851,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.27037983, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "df0a3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "56cb2758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6b9c6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "para='''good boy, good girl, good boy girl'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a410ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ef668e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "14d74f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good boy, good girl, good boy girl']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "56df8904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "747f5330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x3 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5e072a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "obj = TfidfVectorizer()\n",
    "corpus = ['good boy, good girl, good boy girl']\n",
    "X = obj.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "45910e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48507125, 0.48507125, 0.72760688]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab36a72e",
   "metadata": {},
   "source": [
    "data cleaning tweet data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47924c52",
   "metadata": {},
   "source": [
    "1)escaping HTML paser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cb0a5704",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_tweet = \"I luv my &lt;3 iphone &amp; you’re awsm apple. DisplayIsAwesome, sooo happppppy 🙂 http://www.apple.com\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8bf7ef13",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '‘' (U+2018) (Temp/ipykernel_8544/2879355225.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_8544/2879355225.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    tweet = original_tweet.decode(\"utf8\").encode(‘ascii’,’ignore’)\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '‘' (U+2018)\n"
     ]
    }
   ],
   "source": [
    "tweet = original_tweet.decode(\"utf8\").encode(‘ascii’,’ignore’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "52fc4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "obj = TfidfVectorizer()\n",
    "corpus = ['This is sample document.', 'another random document.', 'third sample document text']\n",
    "X = obj.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "77f5462b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is sample document.',\n",
       " 'another random document.',\n",
       " 'third sample document text']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784dda1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5cac8c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.34520502 0.5844829  0.         0.44451431 0.\n",
      "  0.         0.5844829 ]\n",
      " [0.65249088 0.38537163 0.         0.65249088 0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.34520502 0.         0.         0.44451431 0.5844829\n",
      "  0.5844829  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "58a559f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "sentences = [['data', 'science'], ['vidhya', 'science', 'data', 'analytics'],['machine', 'learning'], ['deep', 'learning']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "454f8860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on your corpus  \n",
    "model = Word2Vec(sentences, min_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "084a8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = model.wv.key_to_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "5a333308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning': 0,\n",
       " 'science': 1,\n",
       " 'data': 2,\n",
       " 'deep': 3,\n",
       " 'machine': 4,\n",
       " 'analytics': 5,\n",
       " 'vidhya': 6}"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "93b0d4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index['deep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "33bdde1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=model.wv['analytics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ca50514b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.7274825e-03,  2.1301615e-03, -8.7354420e-04, -9.3190884e-03,\n",
       "       -9.4281426e-03, -1.4107180e-03,  4.4324086e-03,  3.7040710e-03,\n",
       "       -6.4986930e-03, -6.8730675e-03, -4.9994122e-03, -2.2868442e-03,\n",
       "       -7.2502876e-03, -9.6033178e-03, -2.7436293e-03, -8.3628409e-03,\n",
       "       -6.0388758e-03, -5.6709289e-03, -2.3441375e-03, -1.7069972e-03,\n",
       "       -8.9569986e-03, -7.3519943e-04,  8.1525063e-03,  7.6904297e-03,\n",
       "       -7.2061159e-03, -3.6668312e-03,  3.1185520e-03, -9.5707225e-03,\n",
       "        1.4764392e-03,  6.5244664e-03,  5.7464195e-03, -8.7630618e-03,\n",
       "       -4.5171441e-03, -8.1401607e-03,  4.5956374e-05,  9.2636338e-03,\n",
       "        5.9733056e-03,  5.0673080e-03,  5.0610625e-03, -3.2429171e-03,\n",
       "        9.5521836e-03, -7.3564244e-03, -7.2703874e-03, -2.2653891e-03,\n",
       "       -7.7856064e-04, -3.2161034e-03, -5.9258583e-04,  7.4888230e-03,\n",
       "       -6.9751858e-04, -1.6249407e-03,  2.7443992e-03, -8.3591007e-03,\n",
       "        7.8558037e-03,  8.5361041e-03, -9.5840869e-03,  2.4462664e-03,\n",
       "        9.9049713e-03, -7.6658037e-03, -6.9669187e-03, -7.7365171e-03,\n",
       "        8.3959233e-03, -6.8133592e-04,  9.1444086e-03, -8.1582209e-03,\n",
       "        3.7430846e-03,  2.6350426e-03,  7.4271322e-04,  2.3276759e-03,\n",
       "       -7.4690939e-03, -9.3583735e-03,  2.3545765e-03,  6.1484552e-03,\n",
       "        7.9856887e-03,  5.7358947e-03, -7.7733636e-04,  8.3061643e-03,\n",
       "       -9.3363142e-03,  3.4061326e-03,  2.6675343e-04,  3.8572443e-03,\n",
       "        7.3857834e-03, -6.7251669e-03,  5.5844807e-03, -9.5222248e-03,\n",
       "       -8.0445886e-04, -8.6887367e-03, -5.0986730e-03,  9.2892265e-03,\n",
       "       -1.8582619e-03,  2.9144264e-03,  9.0712793e-03,  8.9381328e-03,\n",
       "       -8.2084350e-03, -3.0123137e-03,  9.8866057e-03,  5.1044310e-03,\n",
       "       -1.5880871e-03, -8.6920215e-03,  2.9615164e-03, -6.6758976e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3ee05066",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "a96b153f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['learning', 'science', 'data', 'deep', 'machine', 'analytics', 'vidhya']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8cdfc008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ef6652bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vecattr(\"machine\", \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "68ba03a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('machine', 0.1250143051147461),\n",
       " ('analytics', 0.05258499085903168),\n",
       " ('deep', 0.03897379711270332),\n",
       " ('vidhya', 0.02278798446059227),\n",
       " ('learning', -0.04521758854389191)]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(['data', 'science'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1ba66e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deep', 0.06797593832015991),\n",
       " ('analytics', 0.0093911774456501),\n",
       " ('machine', 0.0045030200853943825),\n",
       " ('learning', -0.010839177295565605),\n",
       " ('data', -0.023671656847000122),\n",
       " ('vidhya', -0.11410721391439438)]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff65ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7f6fde4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on your corpus  \n",
    "model = Word2Vec(corpus, min_count = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "edc57841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three visions india',\n",
       " 'years history people world come invade us capture land conquer mind',\n",
       " 'alexander onwards greeks turks moguls portuguese british french dutch come loot us take',\n",
       " 'yet do nation',\n",
       " 'conquer anyone',\n",
       " 'grab land culture history try enforce way life',\n",
       " '',\n",
       " 'respect freedom others first vision freedom',\n",
       " 'believe india get first vision start war independence',\n",
       " 'freedom must protect nurture build',\n",
       " 'free one respect us',\n",
       " 'second vision india development',\n",
       " 'fifty years develop nation',\n",
       " 'time see develop nation',\n",
       " 'among top nations world term gdp',\n",
       " 'percent growth rate areas',\n",
       " 'poverty level fall',\n",
       " 'achievements globally recognise today',\n",
       " 'yet lack self confidence see develop nation self reliant self assure',\n",
       " 'incorrect',\n",
       " 'third vision',\n",
       " 'india must stand world',\n",
       " 'believe unless india stand world one respect us',\n",
       " 'strength respect strength',\n",
       " 'must strong military power also economic power',\n",
       " 'must go hand hand',\n",
       " 'good fortune work three great mind',\n",
       " 'dr vikram sarabhai dept',\n",
       " 'space professor satish dhawan succeed dr brahm prakash father nuclear material',\n",
       " 'lucky work three closely consider great opportunity life',\n",
       " 'see four milestones career']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9a9476cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "860f80bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'work ' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_8544/3792596302.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'work '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    771\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m                     \u001b[0mall_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \"\"\"\n\u001b[1;32m--> 438\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Key '{key}' not present\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'work ' not present\""
     ]
    }
   ],
   "source": [
    "model.wv.most_similar('work ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "5e26f8e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'india'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_8544/4144355422.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_to_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"india\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'india'"
     ]
    }
   ],
   "source": [
    "model.wv.key_to_index[\"india\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c9077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
