{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b238615",
   "metadata": {},
   "outputs": [],
   "source": [
    "para='''I have three visions for India. In 3000 years of our history'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bad6ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8c46a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences= nltk.sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4944f12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6bc11892",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_15100/2475504261.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpara\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Count' is not defined"
     ]
    }
   ],
   "source": [
    "Count(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d1cf1fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the given string: 8\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Beauty lies in the eyes of 3000  hop beholder\";  \n",
    "wordCount = 0;  \n",
    "   \n",
    "for i in range(0, len(sentence)-1):  \n",
    "    #Counts all the spaces present in the string  \n",
    "    #It doesn't include the first space as it won't be considered as a word  \n",
    "    if(sentence[i] == ' ' and sentence[i+1].isalpha() and (i > 0)):  \n",
    "        wordCount = wordCount + 1;  \n",
    "          \n",
    "  \n",
    "#To count the last word present in the string, increment wordCount by 1  \n",
    "wordCount = wordCount + 1;  \n",
    "   \n",
    "#Displays the total number of words present in the given string  \n",
    "print(\"Total number of words in the given string: \" + str(wordCount));  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17450feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c44c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e342bcb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ba1d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(len(para)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', para[i])\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19f5b49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "017733ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = re.sub('[^a-zA-Z]', '', para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b1e3d3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IhavethreevisionsforIndiaInyearsofourhistory'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "273c6778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0219034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "newline= re.sub(\"[^0-9]\", \" \", para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9625c162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa90f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a748be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d60080e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  review = review.lower()\\n    review = review.split()\\n    review = ' '.join(review)\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''  review = review.lower()\n",
    "    review = review.split()\n",
    "    review = ' '.join(review)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bff73509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb21ec63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have three visions for India. In 3000 years of our history, people from all over \\n               the world have come and invaded us, captured our lands, conquered our minds. \\n               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "19b4069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateScore(text, prefixString, suffixString):\n",
    "    result = {}\n",
    "    lenText = len(text)\n",
    "\n",
    "    while lenText > 0:\n",
    "        for i in range(len(text) + 1 - lenText):\n",
    "            substring = text[i:i + lenText]\n",
    "            \n",
    "            # calc the pre_text_pattern_score\n",
    "            pre_text_pattern_score = min(len(prefixString), len(substring))\n",
    "\n",
    "            while pre_text_pattern_score > 0 and substring[:pre_text_pattern_score] != prefixString[-pre_text_pattern_score:]:\n",
    "                pre_text_pattern_score -= 1\n",
    "            \n",
    "            # calc the post_text_pattern_score\n",
    "            post_text_pattern_score = min(len(suffixString), len(substring))\n",
    "\n",
    "            while post_text_pattern_score > 0 and substring[-post_text_pattern_score:] != suffixString[:post_text_pattern_score]:\n",
    "                post_text_pattern_score-= 1\n",
    "            \n",
    "            # calculate the pattern_score\n",
    "            pattern_score = pre_text_pattern_score + post_text_pattern_score\n",
    "\n",
    "            if not pattern_score in result:\n",
    "                # resets the dictionary key\n",
    "                result[pattern_score] = []\n",
    "\n",
    "            result[pattern_score].append(substring) \n",
    "\n",
    "        lenText -= 1 # reduce lenText by 1\n",
    "\n",
    "    # store the highest key, so we can sort the right item to return   \n",
    "    maximum_pattern_score = max(result.keys())\n",
    "\n",
    "    # make sure to sort the lexicographically lowest string of the highest key\n",
    "    result[maximum_pattern_score].sort()\n",
    "\n",
    "    # return the lexicographically highest key\n",
    "    return result[maximum_pattern_score][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3dafe1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nothing'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculateScore('nothing', 'bruno', 'ingenious')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "32cc8b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculateScore('ab', 'b', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "07d226df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern score of a string:nothing\n",
      "pattern score of a string:a\n"
     ]
    }
   ],
   "source": [
    "def calculatescore(test,prefix,suffix):\n",
    "    result={}\n",
    "    lentest=len(test)\n",
    "    \n",
    "    while lentest>0:\n",
    "        for i in range(len(test)+1-lentest):\n",
    "            sub=test[i:i+lentest]\n",
    "            \n",
    "            #calculate pre-test score\n",
    "            pre_test_score=min(len(prefix),len(sub))\n",
    "            while pre_test_score > 0 and sub[:pre_test_score]!= prefix[-pre_test_score:]:\n",
    "                pre_test_score -= 1\n",
    "             #calculate pre-test score\n",
    "            post_test_score=min(len(suffix),len(sub))\n",
    "            while post_test_score > 0 and sub[:post_test_score]!= suffix[:post_test_score]:\n",
    "                post_test_score -= 1\n",
    "             # calculate the pattern_score   \n",
    "            pattern_score= pre_test_score + post_test_score\n",
    "            if not pattern_score in result:\n",
    "                # resets the dictionary key\n",
    "                result[pattern_score] = []\n",
    "\n",
    "            result[pattern_score].append(substring) \n",
    "    lenText -= 1 # reduce lenText by 1\n",
    "\n",
    "    # store the highest key, so we can sort the right item to return   \n",
    "    maximum_pattern_score = max(result.keys())\n",
    "\n",
    "    # make sure to sort the lexicographically lowest string of the highest key\n",
    "    result[maximum_pattern_score].sort()\n",
    "\n",
    "    # return the lexicographically highest key\n",
    "    return result[maximum_pattern_score][0]\n",
    "print(\"pattern score of a string:\"  + calculateScore('nothing', 'bruno', 'ingenious'))\n",
    "print(\"pattern score of a string:\" +  calculateScore('ab', 'b', 'a'))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "355d7625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nothing'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculateScore('nothing', 'bruno', 'ingenious')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4aff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "from file_operations import file_methods\n",
    "\n",
    "class KMeansClustering:\n",
    "    \"\"\"\n",
    "            This class shall  be used to divide the data into clusters before training.\n",
    "\n",
    "            Written By: iNeuron Intelligence\n",
    "            Version: 1.0\n",
    "            Revisions: None\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "    def __init__(self, file_object, logger_object):\n",
    "        self.file_object = file_object\n",
    "        self.logger_object = logger_object\n",
    "\n",
    "    def elbow_plot(self,data):\n",
    "        \"\"\"\n",
    "                        Method Name: elbow_plot\n",
    "                        Description: This method saves the plot to decide the optimum number of clusters to the file.\n",
    "                        Output: A picture saved to the directory\n",
    "                        On Failure: Raise Exception\n",
    "\n",
    "                        Written By: iNeuron Intelligence\n",
    "                        Version: 1.0\n",
    "                        Revisions: None\n",
    "\n",
    "                \"\"\"\n",
    "        self.logger_object.log(self.file_object, 'Entered the elbow_plot method of the KMeansClustering class')\n",
    "        wcss=[] # initializing an empty list\n",
    "        try:\n",
    "            for i in range (1,11):\n",
    "                kmeans=KMeans(n_clusters=i,init='k-means++',random_state=42) # initializing the KMeans object\n",
    "                kmeans.fit(data) # fitting the data to the KMeans Algorithm\n",
    "                wcss.append(kmeans.inertia_)\n",
    "            plt.plot(range(1,11),wcss) # creating the graph between WCSS and the number of clusters\n",
    "            plt.title('The Elbow Method')\n",
    "            plt.xlabel('Number of clusters')\n",
    "            plt.ylabel('WCSS')\n",
    "            #plt.show()\n",
    "            plt.savefig('preprocessing_data/K-Means_Elbow.PNG') # saving the elbow plot locally\n",
    "            # finding the value of the optimum cluster programmatically\n",
    "            self.kn = KneeLocator(range(1, 11), wcss, curve='convex', direction='decreasing')\n",
    "            self.logger_object.log(self.file_object, 'The optimum number of clusters is: '+str(self.kn.knee)+' . Exited the elbow_plot method of the KMeansClustering class')\n",
    "            return self.kn.knee\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger_object.log(self.file_object,'Exception occured in elbow_plot method of the KMeansClustering class. Exception message:  ' + str(e))\n",
    "            self.logger_object.log(self.file_object,'Finding the number of clusters failed. Exited the elbow_plot method of the KMeansClustering class')\n",
    "            raise Exception()\n",
    "\n",
    "    def create_clusters(self,data,number_of_clusters):\n",
    "        \"\"\"\n",
    "                                Method Name: create_clusters\n",
    "                                Description: Create a new dataframe consisting of the cluster information.\n",
    "                                Output: A datframe with cluster column\n",
    "                                On Failure: Raise Exception\n",
    "\n",
    "                                Written By: iNeuron Intelligence\n",
    "                                Version: 1.0\n",
    "                                Revisions: None\n",
    "\n",
    "                        \"\"\"\n",
    "        self.logger_object.log(self.file_object, 'Entered the create_clusters method of the KMeansClustering class')\n",
    "        self.data=data\n",
    "        try:\n",
    "            self.kmeans = KMeans(n_clusters=number_of_clusters, init='k-means++', random_state=42)\n",
    "            #self.data = self.data[~self.data.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "            self.y_kmeans=self.kmeans.fit_predict(data) #  divide data into clusters\n",
    "\n",
    "            self.file_op = file_methods.File_Operation(self.file_object,self.logger_object)\n",
    "            self.save_model = self.file_op.save_model(self.kmeans, 'KMeans') # saving the KMeans model to directory\n",
    "                                                                                    # passing 'Model' as the functions need three parameters\n",
    "\n",
    "            self.data['Cluster']=self.y_kmeans  # create a new column in dataset for storing the cluster information\n",
    "            self.logger_object.log(self.file_object, 'succesfully created '+str(self.kn.knee)+ 'clusters. Exited the create_clusters method of the KMeansClustering class')\n",
    "            return self.data\n",
    "        except Exception as e:\n",
    "            self.logger_object.log(self.file_object,'Exception occured in create_clusters method of the KMeansClustering class. Exception message:  ' + str(e))\n",
    "            self.logger_object.log(self.file_object,'Fitting the data to clusters failed. Exited the create_clusters method of the KMeansClustering class')\n",
    "            raise Exception()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
